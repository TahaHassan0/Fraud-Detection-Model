{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC REGRESSION; SKLEARN; CLEANED DATA"
      ],
      "metadata": {
        "id": "hmYxmTMOBwxY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5wZMAE59078",
        "outputId": "55ade05c-4b50-4034-930f-77e8ebbf4ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.16%\n",
            "Confusion Matrix:\n",
            "[[2024  466]\n",
            " [  19 2419]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.81      0.89      2490\n",
            "           1       0.84      0.99      0.91      2438\n",
            "\n",
            "    accuracy                           0.90      4928\n",
            "   macro avg       0.91      0.90      0.90      4928\n",
            "weighted avg       0.92      0.90      0.90      4928\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/Fraud.csv')\n",
        "\n",
        "# Encode categorical variables using LabelEncoder\n",
        "encoder = {}\n",
        "for col in df.select_dtypes('object').columns:\n",
        "    encoder[col] = LabelEncoder()\n",
        "    df[col] = encoder[col].fit_transform(df[col])\n",
        "\n",
        "# Separate features (x) and target (y)\n",
        "maskFraud = df['isFraud'] == 1\n",
        "\n",
        "fraud = df[maskFraud]\n",
        "non_fraud = df[maskFraud == False]\n",
        "\n",
        "df_balanced = pd.concat([fraud, non_fraud.sample(len(fraud), random_state= 42)])\n",
        "\n",
        "y = df_balanced['isFraud' ]\n",
        "\n",
        "columns_dropped = [\"step\", \"nameOrig\", \"nameDest\", \"oldbalanceDest\", \"newbalanceDest\", \"isFraud\", \"isFlaggedFraud\"]\n",
        "\n",
        "df_balanced.drop(columns = columns_dropped, inplace = True)\n",
        "\n",
        "X = df_balanced\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy, precision, recall, f1_score = model.evaluate(x_test, y_test)\n",
        "predictions = model.predict(x_test)\n",
        "# # Print evaluation metrics\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC REGRESSION; SELF MODEL; CLEANED DATA"
      ],
      "metadata": {
        "id": "U14Ix4XEB77R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.1, n_iters=2000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for _ in range(self.n_iters):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self._sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "      x = np.clip(x, -500, 500)\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/Fraud.csv')\n",
        "\n",
        "# Encode categorical variables using LabelEncoder\n",
        "encoder = {}\n",
        "for col in df.select_dtypes('object').columns:\n",
        "    encoder[col] = LabelEncoder()\n",
        "    df[col] = encoder[col].fit_transform(df[col])\n",
        "\n",
        "# Separate features (x) and target (y)\n",
        "maskFraud = df['isFraud'] == 1\n",
        "\n",
        "fraud = df[maskFraud]\n",
        "non_fraud = df[maskFraud == False]\n",
        "\n",
        "df_balanced = pd.concat([fraud, non_fraud.sample(len(fraud), random_state= 42)])\n",
        "y = df_balanced['isFraud' ]\n",
        "columns_dropped = [\"step\", \"nameOrig\", \"nameDest\", \"oldbalanceDest\", \"newbalanceDest\", \"isFraud\", \"isFlaggedFraud\"]\n",
        "df_balanced.drop(columns = columns_dropped, inplace = True)\n",
        "X = df_balanced\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Initialize and train the logistic regression model\n",
        "model = LogisticRegression(learning_rate=0.1, n_iters=2000)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# # Evaluate the model\n",
        "\n",
        "predictions = model.predict(x_test)\n",
        "# # Print evaluation metrics\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Print confusion matrix and classification report\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDlD8ZK9-iBg",
        "outputId": "cc528b1f-80cd-4d35-e81d-4d99f970d824"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.50%\n",
            "Confusion Matrix:\n",
            "[[2041  449]\n",
            " [  19 2419]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.82      0.90      2490\n",
            "           1       0.84      0.99      0.91      2438\n",
            "\n",
            "    accuracy                           0.91      4928\n",
            "   macro avg       0.92      0.91      0.90      4928\n",
            "weighted avg       0.92      0.91      0.90      4928\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOGISTIC REGRESSION; SELF MODEL;SCALED VALUES; CLEANED DATA"
      ],
      "metadata": {
        "id": "6NTpdpD9CIT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, learning_rate=0.1, n_iters=2000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for _ in range(self.n_iters):\n",
        "            linear_model = np.dot(X, self.weights) + self.bias\n",
        "            y_predicted = self._sigmoid(linear_model)\n",
        "\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
        "            db = (1 / n_samples) * np.sum(y_predicted - y)\n",
        "\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self._sigmoid(linear_model)\n",
        "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
        "        return np.array(y_predicted_cls)\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        x = np.clip(x, -500, 500)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def preprocess_data(df, scaler):\n",
        "    encoder = {}\n",
        "    for col in df.select_dtypes('object').columns:\n",
        "        encoder[col] = LabelEncoder()\n",
        "        df[col] = encoder[col].fit_transform(df[col])\n",
        "\n",
        "    maskFraud = df['isFraud'] == 1\n",
        "    fraud = df[maskFraud]\n",
        "    non_fraud = df[maskFraud == False]\n",
        "    df_balanced = pd.concat([fraud, non_fraud.sample(len(fraud), random_state=42)])\n",
        "    y = df_balanced['isFraud']\n",
        "    columns_dropped = [\"step\", \"nameOrig\", \"nameDest\", \"oldbalanceDest\", \"newbalanceDest\", \"isFraud\", \"isFlaggedFraud\"]\n",
        "    df_balanced.drop(columns=columns_dropped, inplace=True)\n",
        "    X = df_balanced\n",
        "\n",
        "    # Scale the features\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    return X_scaled, y\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dataset/Fraud.csv')\n",
        "\n",
        "# Create scalers\n",
        "min_max_scaler = MinMaxScaler()\n",
        "standard_scaler = StandardScaler()\n",
        "\n",
        "# Preprocess the data with MinMaxScaler\n",
        "X_mm, y_mm = preprocess_data(df, min_max_scaler)\n",
        "\n",
        "# Preprocess the data with StandardScaler\n",
        "X_ss, y_ss = preprocess_data(df, standard_scaler)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train_mm, x_test_mm, y_train_mm, y_test_mm = train_test_split(X_mm, y_mm, test_size=0.3, random_state=0)\n",
        "x_train_ss, x_test_ss, y_train_ss, y_test_ss = train_test_split(X_ss, y_ss, test_size=0.3, random_state=0)\n",
        "\n",
        "# Initialize and train the logistic regression model with MinMaxScaler\n",
        "model_mm = LogisticRegression(learning_rate=0.1, n_iters=2000)\n",
        "model_mm.fit(x_train_mm, y_train_mm)\n",
        "\n",
        "# Initialize and train the logistic regression model with StandardScaler\n",
        "model_ss = LogisticRegression(learning_rate=0.1, n_iters=2000)\n",
        "model_ss.fit(x_train_ss, y_train_ss)\n",
        "\n",
        "# Evaluate the model with MinMaxScaler\n",
        "predictions_mm = model_mm.predict(x_test_mm)\n",
        "accuracy_mm = accuracy_score(y_test_mm, predictions_mm)\n",
        "print(f\"Accuracy with MinMaxScaler: {accuracy_mm * 100:.2f}%\")\n",
        "print(\"Confusion Matrix with MinMaxScaler:\")\n",
        "print(confusion_matrix(y_test_mm, predictions_mm))\n",
        "print(\"\\nClassification Report with MinMaxScaler:\")\n",
        "print(classification_report(y_test_mm, predictions_mm))\n",
        "\n",
        "# Evaluate the model with StandardScaler\n",
        "predictions_ss = model_ss.predict(x_test_ss)\n",
        "accuracy_ss = accuracy_score(y_test_ss, predictions_ss)\n",
        "print(f\"\\nAccuracy with StandardScaler: {accuracy_ss * 100:.2f}%\")\n",
        "print(\"Confusion Matrix with StandardScaler:\")\n",
        "print(confusion_matrix(y_test_ss, predictions_ss))\n",
        "print(\"\\nClassification Report with StandardScaler:\")\n",
        "print(classification_report(y_test_ss, predictions_ss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGy_bDZ6Awoz",
        "outputId": "35a720c8-16ee-4531-fea6-0635d55d4f0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with MinMaxScaler: 57.22%\n",
            "Confusion Matrix with MinMaxScaler:\n",
            "[[1482 1008]\n",
            " [1100 1338]]\n",
            "\n",
            "Classification Report with MinMaxScaler:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.60      0.58      2490\n",
            "           1       0.57      0.55      0.56      2438\n",
            "\n",
            "    accuracy                           0.57      4928\n",
            "   macro avg       0.57      0.57      0.57      4928\n",
            "weighted avg       0.57      0.57      0.57      4928\n",
            "\n",
            "\n",
            "Accuracy with StandardScaler: 81.15%\n",
            "Confusion Matrix with StandardScaler:\n",
            "[[2313  177]\n",
            " [ 752 1686]]\n",
            "\n",
            "Classification Report with StandardScaler:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.93      0.83      2490\n",
            "           1       0.90      0.69      0.78      2438\n",
            "\n",
            "    accuracy                           0.81      4928\n",
            "   macro avg       0.83      0.81      0.81      4928\n",
            "weighted avg       0.83      0.81      0.81      4928\n",
            "\n"
          ]
        }
      ]
    }
  ]
}